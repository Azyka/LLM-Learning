# LLM-Learning
这是我们在学习LLM理论的同时形成的一个中文入门笔记和文献整理仓库，希望可以帮助到其他初入LLM领域的研究者快速了解领域内的基本概念和技术发展脉络，并逐步从理论过渡到项目实践。

仓库中的大部分文章都可以通过博客进行浏览，也可以在仓库里自行下载。[博客入口](https://llm-frame-group.github.io/)

# 学习流程

## 第一周 - 什么是LLM

第一周我们主要关注LLM领域的基本概念和GPT系列的发展历程。

这周我们采用了泛读的策略，通过阅读综述和大量为LLM奠基的文章，力求对整个领域形成宽泛的认知，并关注一些重点技术原理，如Transformer，GPT等等。



## 第二周 - LLM fine-tune技术

第二周，在认识LLM的实现原理和基本概念的基础上，我们进一步关注如何提高LLM在特定任务上的表现，并引入一些实际的开源项目，看一个真实的开源LLM模型是怎样训练的。

这周我们有策略地对一些更新的技术文章进行了精读，形成论文导读文章，也建议各位入门时对一些很有意思的文章进行深层次的理解，如LoRA的原理和方法。



## 第三周 - LLM prompt技术

第三周我们主要关注prompt相关的技术创新，对使用大语言模型的项目来说，最简便常用的是不需要额外训练的prompt技术，同时prompt也有助于进一步挖掘模型性能。此外，我们还关注了一些之前没关注到的模型优化方法，如Falcon对数据集的调优。

这周我们挑选了近年来认可度高的prompt领域论文进行了技术总结，因为目前有大量的方法被提出，从最新成果中筛选存在难度。同时不同方法之间的联系并不如前两周研究的内容紧密，因此感兴趣的话可以自行调研相关论文进行阅读。
